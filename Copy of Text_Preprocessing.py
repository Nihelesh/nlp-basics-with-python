{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjoHKCU90BsHsRKLDG7f6P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AVMu6gU2qLw0"},"outputs":[],"source":[]},{"cell_type":"code","source":["#Preprocessing of text - Tokenization\n","from nltk.tokenize import TreebankWordTokenizer\n","tokenizer = TreebankWordTokenizer()\n","text = \"Hey! Nihelesh here. I like to study NLP\"\n","tokenizer.tokenize(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YS4kjb3qqjhj","executionInfo":{"status":"ok","timestamp":1765864444466,"user_tz":-330,"elapsed":42,"user":{"displayName":"NIHELESH M U 23CS068","userId":"17311285986819960020"}},"outputId":"9272f2c6-903d-4d32-c5d0-d97254bda5a0"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hey', '!', 'Nihelesh', 'here.', 'I', 'like', 'to', 'study', 'NLP']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Preprocessing of text - Filtration\n","corpus = [\n","    \"Nihelesh loves coding in Python and exploring AI technologies.\",\n","    \"Yesterday, Nihelesh went to the park with his friends.\",\n","    \"Nihelesh's favorite programming language is JavaScript!\",\n","    \"Breaking news: Nihelesh has won the local coding competition.\",\n","    \"<div>Hello Nihelesh, welcome to the NLP workshop!</div>\"\n","]\n","import re\n","import string\n","from bs4 import BeautifulSoup\n","def clean_text(text):\n","  text = text.lower() # Lowercase\n","  text = re.sub(r'\\d+', '', text) # Remove numbers\n","  text = text.translate(str.maketrans('', '', string.punctuation)) #Remove punctuation\n","  text = re.sub(r'\\W', ' ', text) # Remove special characters\n","  text = BeautifulSoup(text, \"html.parser\").get_text() # Remove HTML tags\n","  return text\n","cleaned_corpus = [clean_text(doc) for doc in corpus]\n","for sentence in cleaned_corpus:\n","    print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b2M3nSooquDy","executionInfo":{"status":"ok","timestamp":1765864830753,"user_tz":-330,"elapsed":30,"user":{"displayName":"NIHELESH M U 23CS068","userId":"17311285986819960020"}},"outputId":"80f27dad-2367-4f5e-87e3-370f10955a20"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["nihelesh loves coding in python and exploring ai technologies\n","yesterday nihelesh went to the park with his friends\n","niheleshs favorite programming language is javascript\n","breaking news nihelesh has won the local coding competition\n","divhello nihelesh welcome to the nlp workshopdiv\n"]}]},{"cell_type":"code","source":["#Preprocessing of text - Script Validation\n","import nltk\n","from nltk.metrics.distance import jaccard_distance\n","from nltk.util import ngrams\n","nltk.download('words')\n","from nltk.corpus import words\n","\n","correct_words = words.words()\n","incorrect_words=['happpy', 'loove', 'graetful']\n","\n","for word in incorrect_words:\n","  temp = [(jaccard_distance(set(ngrams(word, 2)),set(ngrams(w, 2))),w)\n","for w in correct_words if w[0]==word[0]]\n","  print(sorted(temp, key = lambda val:val[0])[0][1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDfC-_HksZ7j","executionInfo":{"status":"ok","timestamp":1765865114248,"user_tz":-330,"elapsed":268,"user":{"displayName":"NIHELESH M U 23CS068","userId":"17311285986819960020"}},"outputId":"fa4a500d-7e8c-4350-f869-c3d122b3aeff"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["happy\n","love\n","graceful\n"]}]},{"cell_type":"code","source":["# Preprocessing of text - Stop Word Removal\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","print(stopwords.words('english'))\n","import spacy\n","# Load spaCy English model\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Sample text\n","text = \"Nihelesh likes to play chess\"\n","# Process the text using spaCy\n","doc = nlp(text)\n","\n","# Remove stopwords\n","filtered_words = [token.text for token in doc if not token.is_stop]\n","# Join the filtered words to form a clean text\n","clean_text = ' '.join(filtered_words)\n","print(\"Original Text:\", text)\n","print(\"Text after Stopword Removal:\", clean_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNhcZeAysd6i","executionInfo":{"status":"ok","timestamp":1765865284438,"user_tz":-330,"elapsed":977,"user":{"displayName":"NIHELESH M U 23CS068","userId":"17311285986819960020"}},"outputId":"06c88449-0f90-43b5-8088-7fc85b694727"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n","Original Text: Nihelesh likes to play chess\n","Text after Stopword Removal: Nihelesh likes play chess\n"]}]},{"cell_type":"code","source":["#Preprocessing of text - Stemming\n","import nltk\n","\n","from nltk.stem import PorterStemmer\n","# Create a Porter Stemmer instance\n","porter_stemmer = PorterStemmer()\n","# Example words for stemming\n","words = [\"running\", \"jumps\", \"happily\", \"running\", \"lovely\"]\n","# Apply stemming to each word\n","stemmed_words = [porter_stemmer.stem(word) for word in words]\n","# Print the results\n","print(\"Original words:\", words)\n","print(\"Stemmed words:\", stemmed_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsqD1wNXsiBa","executionInfo":{"status":"ok","timestamp":1765865330427,"user_tz":-330,"elapsed":68,"user":{"displayName":"NIHELESH M U 23CS068","userId":"17311285986819960020"}},"outputId":"ea20892f-4918-431f-91bd-32f277c94bab"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Original words: ['running', 'jumps', 'happily', 'running', 'lovely']\n","Stemmed words: ['run', 'jump', 'happili', 'run', 'love']\n"]}]}]}